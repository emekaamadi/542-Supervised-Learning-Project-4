{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a51a6c24653b5bdb9415de4fbd0ce673",
     "grade": false,
     "grade_id": "cell-c18d184342185ba6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"v2.1.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "# Table of Contents\n",
    "- **[Assignment 4 Description](#Topic0)**\n",
    "  - [Task 1 - Import CSV Sensor Data file](#t1)\n",
    "  - [Task 2 - Standard train_test_split](#t2)\n",
    "  - [Task 3 - Build a baseline Tree model](#t3)\n",
    "  - [Task 4 - Baseline Tree model questions](#t4)\n",
    "  - [Task 5a - A custom train_test_split function](#t5a)\n",
    "  - [Task 5b - Run a baseline_model](#t5b)\n",
    "  - [Task 5c - Custom train/test split questions](#t5c)\n",
    "  - [Task 6 - Confusion Matrix](#t6)\n",
    "    - [Visualizing the Confusion Matrix](#vcm)\n",
    "  - [Task 7 - Basic Confusion Matrix Understanding](#t7)\n",
    "  - [Task 8 - Feature Importance, part 1](#t8)\n",
    "  - [Task 9 - Feature Importance, part 2](#t9)  \n",
    "    - [Scores Plot](#scoresplot)\n",
    "  - [Task 10 - Final project](#t10)\n",
    "    - [Task 10 Autograder Scoring](#t10ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either of the following is no longer\n",
    "# necessary for matplotlib in notebooks.\n",
    "# The import statement has you covered!\n",
    "\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b55e4f31b159cfea2250da44210155f",
     "grade": false,
     "grade_id": "cell-371f2ff64fb68763",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<a id='Topic0'></a>\n",
    "# Assignment 4 - Tree-based classification & Synthesis Project\n",
    "\n",
    "### Physiological Sensor Data Analysis (100 points)\n",
    "This synthesis project is based on a dataset of physiological sensor measurements collected from Smartphone based sensors. The original research sought to determine the particular activity of the subject based on the physiological measurements obtained from wearables and a SmartPhone. The physiological measurements were used to depict the test subject in one of four activities as follows:  \n",
    "   - neutral\n",
    "   - emotional\n",
    "   - mental\n",
    "   - physical  \n",
    " \n",
    "Your task will be to produce a model that, based on a limited number of features, returns the best possible estimate of the activity being performed by the test subject. While the original analysis utilized more advanced Machine Learning methods, we will concentrate on the supervised learning methods covered in this course.  \n",
    "\n",
    "The sensor dataset consists of 4480 rows, each with the subject ID, the activity label and 533 measurement features! Each of the 40 test volunteers were subjected to a series of 28 data collection events for each of the four activity types presented above. As you explore this data, you will find that the features are arranged by a particular measurement mode, each consisting of similar statistical values.  \n",
    "Before we get started, it will be necessary to ingest and prepare our data for training and testing purposes.  \n",
    "\n",
    "**Notes**  \n",
    " - Any available random_state or seed values should be initialized with an integer value of 42.\n",
    " - Some standard package imports have been provided below.\n",
    " - Additional import deemed necessary for your analysis can be added in the cell following.  \n",
    " \n",
    " <a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress all warnings only when absolutely necessary\n",
    "# Warnings are in place for a reason!\n",
    "import warnings\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "# warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f00477711cbe8f337a840b07c1c02d1a",
     "grade": false,
     "grade_id": "cell-93298b856670623e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# useful python standard libraries\n",
    "import itertools\n",
    "import math\n",
    "import random\n",
    "\n",
    "# import core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helpful SciKit-Learn libraries\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d6646c4fd68fa2df4bc6aee78b27488",
     "grade": false,
     "grade_id": "cell-f7bc50deed21528d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "up, down = True, False\n",
    "\n",
    "# path/filename to dataset\n",
    "sensor_data = \"assets/sensor_data.csv\"\n",
    "\n",
    "# We will use this variable name multiple times\n",
    "base_feature_selector = \"_mad_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "## Additional imports can be inlcuded here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f010dcda16b5f35c7adbc46f8fb099d5",
     "grade": false,
     "grade_id": "cell-366227f52585e158",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t1'></a>\n",
    "## Task 1 - Import CSV Sensor Data file (2 points).\n",
    " - The first order of business is to read the data file, '_sensor_data.csv_ ', from the '_assets/_ ' folder.\n",
    " - Your function should accept zero arguments and return a Pandas DataFrame.\n",
    " - Be aware that the activity labels are in a format that may or may not work with your chosen models. If you choose to reassign the activity labels, use the following:  \n",
    "    - **'neutral' == 1**\n",
    "    - **'emotional' == 2**\n",
    "    - **'mental' == 3**\n",
    "    - **'physical' == 4**  \n",
    "    \n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06e9ab7a0c2305465b288755c76090fa",
     "grade": true,
     "grade_id": "cell-df67153258c0d72e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "875e0fb6cee51813a0170950acdfac90",
     "grade": false,
     "grade_id": "cell-323ce9af9affa7e8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_sensor_data():\n",
    "\n",
    "    df = pd.read_csv('assets/sensor_data.csv')\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "# get_sensor_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e834ef5163def337dafd1fe0a829dc0",
     "grade": true,
     "grade_id": "cell-d56b92a082173913",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = get_sensor_data()\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans, pd.DataFrame\n",
    "), \"Task 1: Your get_sensor_data function must return a Pandas DataFrame.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans.iloc[0][2], np.float64\n",
    "), \"Task 1: The dtype of the first row, third column, is incorrect.\"\n",
    "\n",
    "# Some hidden tests\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c08dc744468fcaed7b5222177cbab4fc",
     "grade": false,
     "grade_id": "cell-e309fa31d13a784b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t2'></a>\n",
    "## Task 2 - Standard train_test_split (3 points).\n",
    "\n",
    " - Our first exercise will be to produce a SciKit-Learn standard train/test split of a dataframe. In the following cell, complete the function that returns a standard train/test split of the sensor data.\n",
    "   - The function should accept a dataframe as produced by get_sensor_data() and a test_split value which defaults to 0.2.\n",
    "   - The function should return the standard X_train, X_test, y_train, y_test.  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50375c3bc581d8a9fbde22a2ec35cf87",
     "grade": true,
     "grade_id": "cell-5f1b791501e086cb",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce5eb4171a3dce8386d1757a61a45aba",
     "grade": false,
     "grade_id": "cell-bcd3c8cc8a52f6b7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def std_train_test_split(df, test_split=0.2):\n",
    "    features = df.iloc[:, 2:]\n",
    "    label = df.iloc[:, 1]\n",
    "    X, y = features, label\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = test_split, random_state = 42)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "#X_train, X_test, y_train, y_test = std_train_test_split(get_sensor_data(), test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce4c7be7f35bf7624317f0377d990062",
     "grade": true,
     "grade_id": "cell-aeeea8534654fbda",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 - AG tests\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "df = get_sensor_data()\n",
    "stu_ans = std_train_test_split(df)\n",
    "\n",
    "# print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert isinstance(stu_ans[0], pd.DataFrame), \"Task 2: X_train should be a pd.DataFrame\"\n",
    "\n",
    "assert isinstance(stu_ans[2], pd.Series), \"Task 2: y_train should be a pd.Series\"\n",
    "\n",
    "# Some hidden tests\n",
    "del stu_ans\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca6a005b7f8d434597fa35c5c3a17313",
     "grade": false,
     "grade_id": "cell-fca36043345da8b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t3'></a>\n",
    "## Task 3 - Build a baseline Tree model (5 Points).\n",
    "\n",
    "- Complete the following function that will establish a baseline score.  \n",
    "  - This function should retrieve and split the sensor data based on your previously constructed functions. Please use/default to, a split value of 0.2.  \n",
    "  - Using a _for loop_ or [list comprehension](https://www.w3schools.com/python/python_lists_comprehension.asp), extract a list of feature names that includes the substring **base_feature_selector** defined in the **[library imports](#library-imports)** cell above.  \n",
    "  - Create a [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) with default hyperparameters and the predetermined random_state value.\n",
    "    - Train this model on the features as extracted above.  \n",
    "  - Using the classifier's [score method](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.score), score the model using X_test and the previously extracted subset of features.  \n",
    "  - Finally return a tuple consisting of the list of extracted features and score.  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fdf2880fc2dfc587ab2cbea55883504",
     "grade": true,
     "grade_id": "cell-ecfcc56f82cb1990",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33f22ea3fe3c28b9545331247c9e4e4e",
     "grade": false,
     "grade_id": "cell-d0e06f1c335ec617",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def baseline_model_one():\n",
    "    X_train, X_test, y_train, y_test = std_train_test_split(get_sensor_data(), test_split=0.2)\n",
    "    columns = list(X_train.columns)\n",
    "    features = [x for x in columns if base_feature_selector in x]\n",
    "    clf = DecisionTreeClassifier(random_state = 42).fit(X_train[features], y_train)\n",
    "    score = clf.score(X_test[features], y_test)\n",
    "    \n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return (features, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ECG_original_mad_13',\n",
       "  'ECG_RR_window_mad_27',\n",
       "  'ECG_amplitude_RR_mad_41',\n",
       "  'ECG_HR_min_div_mad_55',\n",
       "  'ECG_hrv_mad_79',\n",
       "  'ECG_PSD_mad_93',\n",
       "  'ECG_p_VFL_mad_107',\n",
       "  'ECG_p_LF_mad_121',\n",
       "  'ECG_p_MF_mad_135',\n",
       "  'ECG_p_HF_mad_149',\n",
       "  'ECG_p_total_LF_mad_163',\n",
       "  'IT_Original_mad_187',\n",
       "  'IT_LF_mad_202',\n",
       "  'IT_RF_mad_217',\n",
       "  'IT_BRV_mad_233',\n",
       "  'IT_PSD_mad_247',\n",
       "  'IT_VLF_mad_261',\n",
       "  'IT_LF_mad_275',\n",
       "  'IT_MF_mad_289',\n",
       "  'IT_HF_mad_303',\n",
       "  'IT_p_Total_mad_317',\n",
       "  'EDA_Original_mad_338',\n",
       "  'EDA_processed_mad_352',\n",
       "  'EDA_Filt1_mad_366',\n",
       "  'EDA_Filt2_mad_380',\n",
       "  'EDA_Original_mad_442',\n",
       "  'EDA_processed_mad_456',\n",
       "  'EDA_Filt1_mad_470',\n",
       "  'EDA_Filt2_mad_484'],\n",
       " 0.8314732142857143)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "baseline_model_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8971b50bd73bef200ba8e1e49d99ccfb",
     "grade": true,
     "grade_id": "cell-3a13464f8906cbe6",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3 - AG tests\n",
      "Task 3 - your answer:\n",
      "(['ECG_original_mad_13', 'ECG_RR_window_mad_27', 'ECG_amplitude_RR_mad_41', 'ECG_HR_min_div_mad_55', 'ECG_hrv_mad_79', 'ECG_PSD_mad_93', 'ECG_p_VFL_mad_107', 'ECG_p_LF_mad_121', 'ECG_p_MF_mad_135', 'ECG_p_HF_mad_149', 'ECG_p_total_LF_mad_163', 'IT_Original_mad_187', 'IT_LF_mad_202', 'IT_RF_mad_217', 'IT_BRV_mad_233', 'IT_PSD_mad_247', 'IT_VLF_mad_261', 'IT_LF_mad_275', 'IT_MF_mad_289', 'IT_HF_mad_303', 'IT_p_Total_mad_317', 'EDA_Original_mad_338', 'EDA_processed_mad_352', 'EDA_Filt1_mad_366', 'EDA_Filt2_mad_380', 'EDA_Original_mad_442', 'EDA_processed_mad_456', 'EDA_Filt1_mad_470', 'EDA_Filt2_mad_484'], 0.8314732142857143)\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "stu_ans = baseline_model_one()\n",
    "print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert isinstance(stu_ans, tuple), \"Task 3: Your function should return a tuple.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans[0], list\n",
    "), \"Task 3: Tuple element zero should be a list object.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans[1], np.float64\n",
    "), \"Task 3: Tuple element one should be a np.float64 value.\"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd00be2fcb2e13c5bd51d825f23426ea",
     "grade": false,
     "grade_id": "cell-3cdcaa635d0d50b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t4'></a>\n",
    "## Task 4 - Baseline Tree model questions (3 Points).\n",
    "\n",
    "1. Does the default accuracy score returned by the model seem reasonable to you; why or why not?\n",
    "2. What might be the problem with this model or with the data?  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dbe07b3481fb5120d11957b6db24684",
     "grade": true,
     "grade_id": "cell-63d35379db6841e9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The default accuracy score seems relatively high for a single decision tree that hasnt been tuned. The model is more accurate when we include all the features. It has a .93 score when all features are included compared to a .83 score with the subset of features. There could be issues with the formatting of the users causing data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "39f6d948d9d0c3636168ae3d50a42ba1",
     "grade": false,
     "grade_id": "cell-6c9f9019196beec7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t5a'></a>\n",
    "## Task 5a- A custom train_test_split function (10 Points).\n",
    "\n",
    " - Because of the nature of the original experiment's data collection methodology, the standard sklearn train_test_split() method cannot be applied successfully to this dataset. \n",
    " - The first significant task will be to create a 'custom_train_test_split()' function that will correctly separate train data from test data, given the structure of the data in the sensor dataset.  \n",
    " - Your function should accept two arguments:  \n",
    "   - A Pandas DataFrame such as returned by your get_sensor_data() function.\n",
    "   - **Note**, your train and test data should **retain** the 'Subject_ID' column!\n",
    "     - This is **NOT** a requirement to use the 'Subject_ID' in the model.\n",
    "   - An integer ___or___ float value that indicates the count or proportion of the **test** data split.\n",
    "   - In accordance with SciKit-Learn standards, split count determinations should round up.\n",
    "   - Again, any random_state or seed values should be initialized with an integer value of 42.\n",
    " - Helpful Libraries and functions:\n",
    "   - [numpy.random](https://numpy.org/doc/stable/reference/random/index.html)\n",
    "     - numpy.random.seed()\n",
    "     - numpy.random.choice()\n",
    "   - Python [math](https://docs.python.org/3/library/math.html)  \n",
    "     - math.ceil()  \n",
    "  \n",
    " - Questions to keep in mind while creating this function:\n",
    "   - How might this function accept and use an integer or float value for the purpose of dividing the dataset?\n",
    "   - How do I ensure consistent random selection for reproducibility?\n",
    "   - Most importantly, how do I split this data to avoid one of the more devastating issues in machine learning?  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0fb95945bd59bdbea9f2953bd36b0634",
     "grade": true,
     "grade_id": "cell-19641eabf59826f7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"5a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f230528117213c81a6b2fd13d6b2160b",
     "grade": false,
     "grade_id": "cell-1618476de514a891",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def custom_train_test_split(df, test_split=0.2):\n",
    "    np.random.seed(42)\n",
    "    ids = df['Subject_ID']\n",
    "    unique_id = list(ids.unique())\n",
    "    if test_split < 1:\n",
    "        test_amount = math.ceil(test_split*40)\n",
    "    else:\n",
    "        test_amount = math.ceil(test_split)\n",
    "    train_id = list(np.random.choice(unique_id, test_amount))\n",
    "    mask = df['Subject_ID'].isin(train_id)\n",
    "    test = df[mask]\n",
    "    mask_train = ~df['Subject_ID'].isin(train_id)\n",
    "    train =  df[mask_train]\n",
    "    X_test = test.drop(test.columns[1], axis=1)\n",
    "    X_train = train.drop(train.columns[1], axis=1)\n",
    "    y_test = test.iloc[:, 1]\n",
    "    y_train = train.iloc[:, 1]\n",
    "    \n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "\n",
    "\n",
    "def test_my_code():\n",
    "    test_split = 5\n",
    "    df = get_sensor_data()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = custom_train_test_split(\n",
    "        df, test_split=test_split\n",
    "    )\n",
    "\n",
    "    print(f\"{df.shape[0]}, {X_train.shape[0]}, {X_test.shape[0]}\")\n",
    "\n",
    "    # insert additional code as necessary to complete your testing\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "# test_my_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8f62714ab54649fd480d96e472f8c15",
     "grade": true,
     "grade_id": "cell-2c97a65714518e45",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3 - AG tests\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "\n",
    "test_split = 5\n",
    "df = get_sensor_data()\n",
    "\n",
    "stu_ans = custom_train_test_split(df, test_split)\n",
    "\n",
    "# print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert isinstance(stu_ans[0], pd.DataFrame), \"Task 5a: X_train should be a pd.DataFrame\"\n",
    "\n",
    "assert isinstance(stu_ans[2], pd.Series), \"Task 5a: y_train should be a pd.Series\"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "736a0029dfa5df3738ac141acc658bd3",
     "grade": false,
     "grade_id": "cell-7bdfb63c135245d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t5b'></a>\n",
    "## Task 5b - Run a baseline_model using your custom data splitter\n",
    "- Copy/Paste your baseline model code from above into the function below.  \n",
    "  - Replace the std_train_test_split() function with your new custom_train_test_split().\n",
    "    - Use the default split of 0.2.\n",
    "  - Run this revised function and answer the questions below.  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dc2020042175358a7cb80bc16c6e7f0",
     "grade": true,
     "grade_id": "cell-3da8d537082beef3",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73b7ba248c227765f6d541fc39bf90ef",
     "grade": false,
     "grade_id": "cell-f837ef40fcc382ee",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def baseline_model_two():\n",
    "    X_train, X_test, y_train, y_test = custom_train_test_split(get_sensor_data(), test_split=0.2)\n",
    "    columns = list(X_train.columns)\n",
    "    features = [x for x in columns if base_feature_selector in x]\n",
    "    clf = DecisionTreeClassifier(random_state = 42).fit(X_train[features], y_train)\n",
    "    score = clf.score(X_test[features], y_test)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return (features, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "# baseline_model_two()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ff0e7610bab57f615424833c3bb75ca",
     "grade": true,
     "grade_id": "cell-72944b90c520abfe",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 5b - AG tests\n",
      "Task 5b - your answer:\n",
      "(['ECG_original_mad_13', 'ECG_RR_window_mad_27', 'ECG_amplitude_RR_mad_41', 'ECG_HR_min_div_mad_55', 'ECG_hrv_mad_79', 'ECG_PSD_mad_93', 'ECG_p_VFL_mad_107', 'ECG_p_LF_mad_121', 'ECG_p_MF_mad_135', 'ECG_p_HF_mad_149', 'ECG_p_total_LF_mad_163', 'IT_Original_mad_187', 'IT_LF_mad_202', 'IT_RF_mad_217', 'IT_BRV_mad_233', 'IT_PSD_mad_247', 'IT_VLF_mad_261', 'IT_LF_mad_275', 'IT_MF_mad_289', 'IT_HF_mad_303', 'IT_p_Total_mad_317', 'EDA_Original_mad_338', 'EDA_processed_mad_352', 'EDA_Filt1_mad_366', 'EDA_Filt2_mad_380', 'EDA_Original_mad_442', 'EDA_processed_mad_456', 'EDA_Filt1_mad_470', 'EDA_Filt2_mad_484'], 0.5727040816326531)\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "stu_ans = baseline_model_two()\n",
    "\n",
    "print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert isinstance(stu_ans, tuple), \"Task 5b: Your function should return a tuple.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans[0], list\n",
    "), \"Task 5b: Tuple element zero should be a list object.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans[1], np.float64\n",
    "), \"Task 5b: Tuple element one should be a np.float64 value.\"\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b81f5a7173db01fec2ef9bf8926c527",
     "grade": false,
     "grade_id": "cell-21809bc2608e0994",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t5c'></a>\n",
    "## Task 5c - Custom train/test split questions (2 Points).\n",
    "\n",
    "1. Is the score of the model that incorporates custom_train_test_split() significantly different from the std_train_test_split() version?  \n",
    "2. What issue(s) have we eliminated with our new custom_train_test_split() function?  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c97c9a253e5e8eec91e31911e863cd57",
     "grade": true,
     "grade_id": "cell-175bb32a2a2293c4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The model is performing significantly worse than it did using the std_train_test_split(). This is because we eliminated the data leakage that was occuring by allowing teh same user to have rowsa in the test set and the train set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "100121314bbd7477eb138872a8ea2439",
     "grade": false,
     "grade_id": "cell-2e0f6b0e6c8930f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t6'></a>\n",
    "## Task 6 - Confusion Matrix (5 Points).\n",
    "\n",
    " - We now want to better understand the relationship of correct and incorrect predictons made by a classification model. A very useful tool for examining a multiclass outcome, such as we have with our sensor dataset, is the [Confusion Matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix)\n",
    " - Using the SciKit-Learn [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) model, create a function that returns a Confusion Matrix.\n",
    "   - Your function should accept zero arguments.  \n",
    "   - Set hyperparameter: max_iter=1000\n",
    "   - Any random_state or seed values should be initialized with an integer value of 42.\n",
    " - Use your previously defined functions to derive your train and test sets.\n",
    " - Scaling is an important factor in many Machine Learning projects (See section 3.3 in the course textbook). For the current dataset, use the sklearn method StandardScaler() to scale the train and test sets.\n",
    " - Using code that you had previously developed, include all features who's name includes the substring defined in \n",
    "**base_feature_selector** ([library imports](#library-imports)).\n",
    "- Your function should return the following tuple:  \n",
    "   - The confusion matrix array as returned by the sklean method confusion_matrix().  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "889f01ae32fe15408e098823a77c9623",
     "grade": true,
     "grade_id": "cell-31043e0e4351d70e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a012cb704df6542e0f0fc22bbd1a833e",
     "grade": false,
     "grade_id": "cell-02b6f1ff73a7c6a8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def LR_confusion_matrix():\n",
    "    X_train, X_test, y_train, y_test = custom_train_test_split(get_sensor_data(), test_split=0.2)\n",
    "    scaler = StandardScaler()\n",
    "    columns = list(X_train.columns)\n",
    "    features = [x for x in columns if base_feature_selector in x]\n",
    "    X_train = X_train[features]\n",
    "    X_test = X_test[features]\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    clf = LogisticRegression(random_state=42, max_iter=1000).fit(X_train_scaled, y_train)\n",
    "    X_predict = clf.predict(X_test_scaled)\n",
    "    conf_matrix = confusion_matrix(y_test, X_predict)\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 68,  61,   0,  67],\n",
       "        [ 70,  71,   0,  55],\n",
       "        [ 27,  52,  82,  35],\n",
       "        [  5,  27,   0, 164]]),\n",
       " 0.49107142857142855)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "#LR_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c48dcf1305089a7949ec4b53648e30ad",
     "grade": true,
     "grade_id": "cell-9ce7903f9c06f5f5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 5b - AG tests\n",
      "Task 5b - your answer:\n",
      "[[ 68  61   0  67]\n",
      " [ 70  71   0  55]\n",
      " [ 27  52  82  35]\n",
      " [  5  27   0 164]]\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "stu_ans = LR_confusion_matrix()\n",
    "\n",
    "print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans, np.ndarray\n",
    "), \"Task 6: The second tuple element should be an np.ndarray\"\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef11b7c4d3fae4bfdde4f5936c08cf03",
     "grade": false,
     "grade_id": "cell-4c32db5c2bff0137",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='vcm'></a>\n",
    "## Visualizing the Confusion Matrix\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8e666ad0ca9607d5bf7f7e7f59d246b",
     "grade": false,
     "grade_id": "cell-740465ee9e481736",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion():\n",
    "    cm = LR_confusion_matrix()\n",
    "    labels = {\"neutral\": 1, \"emotional\": 2, \"mental\": 3, \"physical\": 4}.keys()\n",
    "    display_cm = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    display_cm.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "plot_confusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "12a957b449585b003807a0e6e5f0eb14",
     "grade": false,
     "grade_id": "cell-3a8431087ad8d20c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id='t7'></a>\n",
    "## Task 7 - Basic Confusion Matrix Understanding (5 Points).\n",
    "\n",
    " - Answer the following questions concerning the above Confusion Matrix.  \n",
    " - Record (hardcode) your answers in the answer variables in the cell below for autograding purposes.  \n",
    " - Your answers should use the Python types **int**, **float**, or **str** as appropriate.\n",
    " \n",
    "Q1. What is the number of __Correctly Predicted__ for the _mental_ activity?  \n",
    "Q2. How many __False Positive__ predictions were made for the _neutral_ activity?  \n",
    "Q3. How many __False Negative__ predictions were made for the _physical_ activity?  \n",
    "Q4. What is the __Precision__ Score for the _mental_ activity? (round to three decimal places)  \n",
    "Q5. What is the __Recall__ Score for the _emotional_ activity? (round to three decimal places)  \n",
    "Q6. What is the overall __Accuracy__ for the current model? (round to three decimal places)  \n",
    "Q7. Which activity is most confused for _mental_ activity when not?  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fab445f7002d62016b0483847a49d2a2",
     "grade": true,
     "grade_id": "cell-0a69762d0a229166",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98503243f5c05907a8b5b172aaf3ea60",
     "grade": false,
     "grade_id": "cell-aa8a1e16f3e1108a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Supply your answers to Q1 through Q7\n",
    "# in variables a1 through a7.\n",
    "\n",
    "\n",
    "def confusion_matrix_questions():\n",
    "\n",
    "    a1 = 82\n",
    "    a2 = 102\n",
    "    a3 = 32\n",
    "    a4 = 82/82\n",
    "    a5 = round(71/196,3)\n",
    "    a6 = round(0.49107142857142855,3)\n",
    "    a7 = 'neutral'\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return (a1, a2, a3, a4, a5, a6, a7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "991d7f9808520d524f91af303c5d6b46",
     "grade": true,
     "grade_id": "cell-6c520b1fae9d0a50",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3 - AG tests\n",
      "Task 3 - your answer:\n",
      "(82, 102, 32, 1.0, 0.362, 0.491, 'neutral')\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "stu_ans = confusion_matrix_questions()\n",
    "\n",
    "print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert (\n",
    "    len(stu_ans) == 7\n",
    "), \"Task 7: Your answer tuple does not contain the correct number of answers.\"\n",
    "assert isinstance(stu_ans[0], int), \"Task 7: Answer one should be an integer\"\n",
    "assert isinstance(stu_ans[1], int), \"Task 7: Answer two should be an integer\"\n",
    "assert isinstance(stu_ans[2], int), \"Task 7: Answer three should be an integer\"\n",
    "assert isinstance(stu_ans[3], float), \"Task 7: Answer four should be a float\"\n",
    "assert isinstance(stu_ans[4], float), \"Task 7: Answer five should be a float\"\n",
    "assert isinstance(stu_ans[5], float), \"Task 7: Answer six should be a float\"\n",
    "assert isinstance(stu_ans[6], str), \"Task 7: Answer seven should be a string\"\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b77416d3cbdbf0726f6d02d69c434766",
     "grade": false,
     "grade_id": "cell-1aeefba857843791",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t8'></a>\n",
    "## Task 8 - Feature Importance, part 1 (5 Points).\n",
    "#### Now we want to explore how some models are able to provide additional insight into the features that played a prominent role in the estimation outcome.\n",
    " - Produce a function that implements a RandomForestClassifier model, which includes the [**feature_importances_**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.feature_importances_) attribute.\n",
    "- The function accepts a single argument for the top X number of features, the default value will be 10.\n",
    "  - The classifier should use only two parameters:\n",
    "    - random_state=42\n",
    "    - n_jobs=-1\n",
    "- Use your previously defined functions to derive your train and test sets.\n",
    "- Using code that you had previously developed, include all features who's name includes the substring defined by **base_feature_selector** ([library imports](#library-imports)).\n",
    " - The function should return a tuple of two elements.\n",
    "   - The first element will be a **sorted** list of tuples in the form **\\[('feature_name', importance_value),...\\]**. The list of tuples should be sorted in descending order.\n",
    "     - This list of tuples should be sorted in **descending order** of feature_importance.\n",
    "   - The second element (test data score) should be an np.float64 value.  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c296f586bf90361275af27ae360a7e16",
     "grade": true,
     "grade_id": "cell-74def7d945e536be",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3235be835faf0804ca3bf3a2699dab4",
     "grade": false,
     "grade_id": "cell-ffe4926e6361f5fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_top_features(top=10):\n",
    "    X_train, X_test, y_train, y_test = custom_train_test_split(get_sensor_data(), test_split=0.2)\n",
    "    columns = list(X_train.columns)\n",
    "    features = [x for x in columns if base_feature_selector in x]\n",
    "    X_train = X_train[features]\n",
    "    X_test = X_test[features]\n",
    "    clf = RandomForestClassifier(random_state=42,n_jobs=-1).fit(X_train, y_train)\n",
    "    score = clf.score(X_test,y_test)\n",
    "    importance = list(clf.feature_importances_)\n",
    "    tuple_list = []\n",
    "    for i,item in enumerate(importance):\n",
    "        tuple_list.append((features[i],importance[i]))\n",
    "    top_x = sorted(tuple_list, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return top_x[:top], score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('IT_Original_mad_187', 0.113324672271813),\n",
       "  ('IT_LF_mad_202', 0.09616450244880041),\n",
       "  ('IT_RF_mad_217', 0.07129356671824066),\n",
       "  ('ECG_original_mad_13', 0.0681501351841329),\n",
       "  ('ECG_amplitude_RR_mad_41', 0.056582143969032994),\n",
       "  ('IT_p_Total_mad_317', 0.0450656073059221),\n",
       "  ('EDA_processed_mad_456', 0.041855793830785686),\n",
       "  ('IT_PSD_mad_247', 0.04057596959789773),\n",
       "  ('ECG_RR_window_mad_27', 0.036839827826773086),\n",
       "  ('ECG_HR_min_div_mad_55', 0.036048175056046704)],\n",
       " 0.5446428571428571)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "get_top_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33997807dc9ed420c60c46bb6e41404f",
     "grade": true,
     "grade_id": "cell-b112a369a5bef4a9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 8 - AG tests\n",
      "Task 8 - your answer:\n",
      "([('IT_Original_mad_187', 0.113324672271813), ('IT_LF_mad_202', 0.09616450244880041), ('IT_RF_mad_217', 0.07129356671824066), ('ECG_original_mad_13', 0.0681501351841329), ('ECG_amplitude_RR_mad_41', 0.056582143969032994), ('IT_p_Total_mad_317', 0.0450656073059221), ('EDA_processed_mad_456', 0.041855793830785686), ('IT_PSD_mad_247', 0.04057596959789773), ('ECG_RR_window_mad_27', 0.036839827826773086), ('ECG_HR_min_div_mad_55', 0.036048175056046704)], 0.5446428571428571)\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "stu_ans = get_top_features()\n",
    "\n",
    "print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert (\n",
    "    len(stu_ans) == 2\n",
    "), \"Task 8: Your answer tuple does not contain the correct number of elements.\"\n",
    "\n",
    "assert isinstance(stu_ans[0], list), \"Task 9: The first tuple element should be a list\"\n",
    "\n",
    "assert (\n",
    "    len(stu_ans[0]) == 10\n",
    "), \"Task 9: The default number of top features is not correct.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans[1], np.float64\n",
    "), \"Task 9: get_top_features() second return element should be an np.float64.\"\n",
    "\n",
    "del stu_ans\n",
    "\n",
    "# Some hidden tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a70c8c9fddfba76b593c63a57326abc1",
     "grade": false,
     "grade_id": "cell-0562af8e13d94e4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t9'></a>\n",
    "## Task 9 - Feature Importance, part 2 (10 Points).\n",
    "\n",
    "#### The value of Feature Importance \n",
    "- This follow-on task will use the same **RandomForestClassifier** model as in your get_top_features() function.\n",
    "- The new model will use a portion of the output returned by the get_top_features() function.\n",
    "- Use the previously defined functions to derive your train and test datasets.\n",
    "- Create a loop that trains your model with an incrementally increasing number of features from the top features list.\n",
    "  - The first pass will include the topmost important feature, the second pass will include the top two most important features and so on until the final pass of all top X features.\n",
    "- Your function should return a list of feature-based test data scores produced by the model.  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5153385992ff7bd1228d9a5635c03f1",
     "grade": true,
     "grade_id": "cell-f85b4f97ca14b2b6",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c60dd666af9160639df3e8dfbb0461e2",
     "grade": false,
     "grade_id": "cell-61533567ca475486",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def score_top_features(top=10):\n",
    "    X_train, X_test, y_train, y_test = custom_train_test_split(get_sensor_data(), test_split=0.2)\n",
    "    columns = list(X_train.columns)\n",
    "    features = [x for x in columns if base_feature_selector in x]\n",
    "    X_train_feat = X_train[features]\n",
    "    X_test_feat = X_test[features]\n",
    "    clf = RandomForestClassifier(random_state=42,n_jobs=-1).fit(X_train_feat, y_train)\n",
    "    score = clf.score(X_test_feat,y_test)\n",
    "    importance = list(clf.feature_importances_)\n",
    "    tuple_list = []\n",
    "    for i,item in enumerate(importance):\n",
    "        tuple_list.append((features[i],importance[i]))\n",
    "    top_x = sorted(tuple_list, key=lambda x: x[1], reverse=True)\n",
    "    top_x = top_x[:top]\n",
    "    scores = []\n",
    "    temp_features =[]\n",
    "    for item in top_x:\n",
    "        temp_features.append(item[0])\n",
    "        clf = RandomForestClassifier(random_state=42,n_jobs=-1).fit(X_train[temp_features], y_train)\n",
    "        score = clf.score(X_test_feat[temp_features],y_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "# score_top_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06177e994c63dd06acd34152b9520e0b",
     "grade": true,
     "grade_id": "cell-bbade458d0c15e25",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - AG tests\n",
      "Task 1 - your answer:\n",
      "[0.39413265306122447, 0.43112244897959184, 0.44387755102040816, 0.44387755102040816, 0.45663265306122447, 0.5510204081632653, 0.5357142857142857, 0.5612244897959183, 0.5752551020408163, 0.5956632653061225]\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "top = 10\n",
    "stu_ans = score_top_features(top)\n",
    "\n",
    "print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert (\n",
    "    len(stu_ans) == top\n",
    "), \"Task 9: Your function does not return the correct number of scores.\"\n",
    "\n",
    "assert all(\n",
    "    isinstance(x, np.float64) for x in stu_ans\n",
    "), \"Task 9: One or more of the returned scores is of an incorrect type.\"\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71dfe7a3b12c5d5bc18546340f41e1fc",
     "grade": false,
     "grade_id": "cell-394cc694e2554086",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='scoresplot'></a>\n",
    "## Scores Plot\n",
    "The plot_scores() function accepts top X features argumnet which defaults to a value of 10. Feel free to change the argument to better see how accuracy is affected by the number of top features used to train the model.  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "149bc8e99b66731b538ec3f9641b9f10",
     "grade": false,
     "grade_id": "cell-8fe2a304ac06b8b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_scores(top=10):\n",
    "\n",
    "    if top > 29:\n",
    "        top = 29\n",
    "\n",
    "    top_x_features, score = get_top_features(top)\n",
    "    scores = score_top_features(top)\n",
    "\n",
    "    importance_scores = [score[1] for score in top_x_features]\n",
    "    x_axis = np.arange(1, len(scores) + 1)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    plt.xticks(x_axis)\n",
    "    plt.ylim([0, max(score, max(importance_scores)) + 0.05])\n",
    "    plt.xlabel(\"Number of Top 10 Features Used\")\n",
    "    plt.ylabel(\"Score Value\")\n",
    "    plt.grid(alpha=0.25)\n",
    "\n",
    "    plt.plot(x_axis, scores, label=\"Accuracy Score\", c=\"g\", linestyle=\"solid\")\n",
    "\n",
    "    plt.plot(\n",
    "        x_axis,\n",
    "        importance_scores,\n",
    "        label=\"Feature Importance Scores\",\n",
    "        c=\"r\",\n",
    "        linestyle=\"solid\",\n",
    "    )\n",
    "\n",
    "    plt.axhline(\n",
    "        score,\n",
    "        label=f\"All '{base_feature_selector}' features score\",\n",
    "        c=\"b\",\n",
    "        linestyle=\"dashed\",\n",
    "    )\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy vs feature importance\n",
    "# the plot_scores() function accepts an optional top N parameter.\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "# plot_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b37a65c6c13fd22b71a9f4b58df0ebff",
     "grade": false,
     "grade_id": "cell-4e84ab0e7aaf6f51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t10'></a>\n",
    "## Task 10 - Final project (50 Points).\n",
    "\n",
    "- The final task for this assignment is open-ended with only a few **constraints**. Using any of the Supervised Machine Learning techniques and models presented in this course, produce a model that produces a best-possible ROC-AUC score. Your Task 10 award points will be evaluated solely on this score. The primary constraint for this task is that you will be able to utilize not more than **10** of the 533 available data features in the training and scoring of your model. A quick calculation of the number of available combinations C(n, r) = C(533, 10) = $\\frac{n!}{r!(n-r)!}$ = 4.684e20. That is very large number of possible combinations (the number of permutations is even greater)! Because of the intractability of checking all possible 10-feature combinations, it will be necessary to devise a scheme whereby your algorithm makes a selection of features and scores that selection. Be creative but also efficient in your feature selection process; this may well mean computational efficiency. Attempting to examine too many features at one time can be computationally very expensive! Because multiple feature selection cycles may be necessary, you will also need to develop an efficient method of keeping track of the top model, features, and score.  \n",
    "\n",
    "- Why would we want to limit the number of features? \n",
    "   1. The creator of the project may want to minimize the number of sensors/measurements required to move the project forward.\n",
    "   2. The final product will be used on a smartphone where resource consumption is always a concern.\n",
    "   3. Computational resource availability of the development environment could be constrained due to budget availability.\n",
    "   4. The development environment may be intentionally constrained to mimic the production environment.\n",
    "  \n",
    "- You will find that even with these limitations, some model choices will still consume significant resources, even to the point of crashing the Python kernel!  \n",
    "\n",
    "- The activity_model() function:\n",
    "  - Arguments: none\n",
    "  - Use your previously defined functions to derive your train and test sets.\n",
    "  - If feasible, expand upon your previously created feature selection code.\n",
    "  - Use the following parameters when establishing your [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) method:\n",
    "    - average=\"macro\"\n",
    "    - multi_class=\"ovr\"\n",
    "  - return: a tuple consisting of (fit_model, feature_list, roc_auc_score)  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10e9807495e332a7cc98a573fd27cb34",
     "grade": true,
     "grade_id": "cell-25d9f52ee1c53c77",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d13d8ecd713b4ed9d58940ec96042792",
     "grade": false,
     "grade_id": "cell-aa54eef9e0c09556",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def activity_model():\n",
    "    \n",
    "    # Used the comment block  below to find the important features, then I found that the features that started with IT \n",
    "    # were having the biggest impact along with the GradientBoostingClassifier. So I ran a large random test on the best 50 starting with It to find the specific set of best\n",
    "    # 10 that were used at the bottom. Then optimized that best 10. \n",
    "    import random\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    X_train, X_test, y_train, y_test = custom_train_test_split(get_sensor_data(), test_split=0.2)\n",
    "    X_train = X_train.iloc[:,1:]\n",
    "    X_test = X_test.iloc[:,1:]\n",
    "    columns = list(X_train.columns)\n",
    "    features = [x for x in columns if x.startswith('IT')]\n",
    "    temp = RandomForestClassifier(random_state=42,n_jobs=-1).fit(X_train[features], y_train)\n",
    "    score = temp.score(X_test[features],y_test)\n",
    "    importance = list(temp.feature_importances_)\n",
    "    tuple_list = []\n",
    "    for i,item in enumerate(importance):\n",
    "        tuple_list.append((X_train[features].columns[i],importance[i]))\n",
    "    top_x = sorted(tuple_list, key=lambda x: x[1], reverse=True)\n",
    "    top_features = top_x[:50]\n",
    "    top_features_only = [val[0] for val in top_features]\n",
    "\n",
    "\n",
    "    \n",
    "    '''\n",
    "    # List to store the results\n",
    "    results = []\n",
    "    random.seed(42)\n",
    "    # Loop through 10 sets of 10 randomly chosen features\n",
    "    for i in range(50):\n",
    "        # Choose 10 random features\n",
    "        features = random.sample(top_features_only, 10)\n",
    "\n",
    "        # Create and train the Decision Tree model\n",
    "        model = DecisionTreeClassifier(random_state=42)\n",
    "        model.fit(X_train[features], y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = model.predict_proba(X_test[features])\n",
    "\n",
    "        # Calculate and store the ROC-AUC score\n",
    "        score = roc_auc_score(y_test, y_pred,average=\"macro\", multi_class=\"ovr\")\n",
    "        results.append((features, model, score))\n",
    "\n",
    "        # Repeat the process for the Random Forest, Gradient Boosting, KNN, and SVM models\n",
    "        model = RandomForestClassifier(random_state=42,n_jobs=-1)\n",
    "        model.fit(X_train[features], y_train)\n",
    "        y_pred = model.predict_proba(X_test[features])\n",
    "        score = roc_auc_score(y_test, y_pred,average=\"macro\", multi_class=\"ovr\")\n",
    "        results.append((features, model, score))\n",
    "\n",
    "        model = GradientBoostingClassifier(random_state=42)\n",
    "        model.fit(X_train[features], y_train)\n",
    "        y_pred = model.predict_proba(X_test[features])\n",
    "        score = roc_auc_score(y_test, y_pred,average=\"macro\", multi_class=\"ovr\")\n",
    "        results.append((features, model, score))\n",
    "\n",
    "        model = KNeighborsClassifier()\n",
    "        model.fit(X_train[features], y_train)\n",
    "        y_pred = model.predict_proba(X_test[features])\n",
    "        score = roc_auc_score(y_test, y_pred,average=\"macro\", multi_class=\"ovr\")\n",
    "        results.append(( model,features,score))\n",
    "        highest_tuple = max(results, key=lambda t: t[2])\n",
    "    '''\n",
    "        # YOUR CODE HERE\n",
    "        # List to store the results\n",
    "    results = []\n",
    "    random.seed(42)\n",
    "    # Loop through 10 sets of 10 randomly chosen features\n",
    "    # Choose 10 random features\n",
    "    features = ['IT_LF_mean_190',\n",
    "       'IT_RF_baseline_218',\n",
    "       'IT_RF_std_206',\n",
    "       'IT_VLF_baseline_262',\n",
    "       'IT_LF_std_191',\n",
    "       'IT_Original_min_182',\n",
    "       'IT_VLF_median_252',\n",
    "       'IT_VLF_max_255',\n",
    "       'IT_RF_Area_219',\n",
    "       'IT_RF_skewness_209']\n",
    "\n",
    "    model = GradientBoostingClassifier(random_state=42, max_depth =4,learning_rate = 0.2, n_estimators = 250)\n",
    "    model.fit(X_train[features], y_train)\n",
    "    y_pred = model.predict_proba(X_test[features])\n",
    "    score = roc_auc_score(y_test, y_pred,average=\"macro\", multi_class=\"ovr\")\n",
    "    results.append(( model, features,score))\n",
    "    highest_tuple = max(results, key=lambda t: t[2])\n",
    "\n",
    "        #raise NotImplementedError()\n",
    "\n",
    "    return highest_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['IT_LF_mean_190',\n",
       "  'IT_RF_baseline_218',\n",
       "  'IT_RF_std_206',\n",
       "  'IT_VLF_baseline_262',\n",
       "  'IT_LF_std_191',\n",
       "  'IT_Original_min_182',\n",
       "  'IT_VLF_median_252',\n",
       "  'IT_VLF_max_255',\n",
       "  'IT_RF_Area_219',\n",
       "  'IT_RF_skewness_209'],\n",
       " GradientBoostingClassifier(learning_rate=0.2, max_depth=4, n_estimators=250,\n",
       "                            random_state=42),\n",
       " 0.8901347528807441)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "activity_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t10ag'></a>\n",
    "## Task 10 Autograder Scoring\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f18f6f816490cdef3c7a628c8f00678b",
     "grade": true,
     "grade_id": "cell-b75d744376ca0a86",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 8 - AG tests\n",
      "Task 8 - your answer:\n",
      "(GradientBoostingClassifier(learning_rate=0.2, max_depth=4, n_estimators=250,\n",
      "                           random_state=42), ['IT_LF_mean_190', 'IT_RF_baseline_218', 'IT_RF_std_206', 'IT_VLF_baseline_262', 'IT_LF_std_191', 'IT_Original_min_182', 'IT_VLF_median_252', 'IT_VLF_max_255', 'IT_RF_Area_219', 'IT_RF_skewness_209'], 0.8901347528807441)\n"
     ]
    }
   ],
   "source": [
    "# Hidden autograder model validation\n",
    "# test for AUC score >= 0.83\n",
    "\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "stu_ans = activity_model()\n",
    "\n",
    "print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "\n",
    "assert (\n",
    "    stu_ans[2] >= 0.83\n",
    "), f\"Task 10: Your test AUC {stu_ans[2]:.4f} is less than 0.83. You will not receive any points for this task.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a8a650f365fb75e4b394750f061a15f",
     "grade": true,
     "grade_id": "cell-51c43ad464c6a07b",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder test - AUC >= 0.85\n",
    "\n",
    "\n",
    "assert (\n",
    "    stu_ans[2] >= 0.85\n",
    "), f\"Task 10: Your test AUC {stu_ans[2]:.4f} is less than 0.85. You will receive 25 points for this task.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65265237510370aab9f17f05ca174c41",
     "grade": true,
     "grade_id": "cell-8013377ff7931f48",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder test - AUC >= 0.87\n",
    "\n",
    "\n",
    "assert (\n",
    "    stu_ans[2] >= 0.87\n",
    "), f\"Task 10: Your test AUC {stu_ans[2]:.4f} is less than 0.87. You will receive 30 points for this task.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93cd28cd440d1f6ab2b2e4de33f5f63f",
     "grade": true,
     "grade_id": "cell-ebe32e8d5f5255f4",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder test - AUC >= 0.89\n",
    "\n",
    "\n",
    "assert (\n",
    "    stu_ans[2] >= 0.89\n",
    "), f\"Task 10: Your test AUC {stu_ans[2]:.4f} is less than 0.89. You will receive 35 points for this task.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ad18ab63b716f46b31afae3e89d8b60",
     "grade": true,
     "grade_id": "cell-ee59bccdda8ea14c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Task 10: Your test AUC 0.8901 is less than 0.91. You will receive 45 points for this task.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [168]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# autograder test - AUC >= 0.91\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     stu_ans[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.91\u001b[39m\n\u001b[1;32m      6\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask 10: Your test AUC \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstu_ans[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is less than 0.91. You will receive 45 points for this task.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m stu_ans\n",
      "\u001b[0;31mAssertionError\u001b[0m: Task 10: Your test AUC 0.8901 is less than 0.91. You will receive 45 points for this task."
     ]
    }
   ],
   "source": [
    "# autograder test - AUC >= 0.91\n",
    "\n",
    "\n",
    "assert (\n",
    "    stu_ans[2] >= 0.91\n",
    "), f\"Task 10: Your test AUC {stu_ans[2]:.4f} is less than 0.91. You will receive 45 points for this task.\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "coursera": {
   "schema_names": [
    "mads_supervised_learning_v2_assignment4"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
